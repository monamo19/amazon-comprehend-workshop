{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Comprehend Custom Classification - Lab\n",
    "\n",
    "This notebook will serve as a template for the overall process of taking a text dataset and integrating it into [Amazon Comprehend Custom Classification](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html) and perform NLP for custom classification.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. [Introduction to Amazon Comprehend Custom Classification](#Introduction)\n",
    "1. [Obtaining Your Data](#data)\n",
    "1. [Pre-processing data](#preprocess)\n",
    "1. [Building Custom Classification model](#build)\n",
    "1. [Evaluate Custom Classification model](#evaluate)\n",
    "1. [Cleanup](#cleanup)\n",
    "\n",
    "\n",
    "## Introduction to Amazon Comprehend Custom Classification <a class=\"anchor\" id=\"Introduction\"/>\n",
    "\n",
    "If you are not familiar with Amazon Comprehend Custom Classification you can learn more about this tool on these pages:\n",
    "\n",
    "* [Product Page](https://aws.amazon.com/comprehend/)\n",
    "* [Product Docs](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html)\n",
    "\n",
    "\n",
    "## Obtaining Your Data <a class=\"anchor\" id=\"data\"/>\n",
    "\n",
    "We are going to use DBPedia ontology corpus used in “[Character-level Convolutional Networks for Text Classification](https://arxiv.org/abs/1509.01626)” paper by Xiang Zhang, Junbo Zhao, Yann LeCun. This dataset is made available on the AWS [Open Data Registry](https://registry.opendata.aws/fast-ai-nlp/).\n",
    "\n",
    "To begin the cell below will complete the following:\n",
    "\n",
    "1. Create a directory for the data files.\n",
    "1. Download the sample data into the directory.\n",
    "1. Extract the archive file into the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir nlp_data\n",
    "!cd nlp_data && wget https://s3.amazonaws.com/fast-ai-nlp/dbpedia_csv.tgz\n",
    "!cd nlp_data && tar -zxvf dbpedia_csv.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data downloaded, now we will import the Pandas library as well as a few other data science tools in order to inspect the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import secrets\n",
    "import string\n",
    "import datetime \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the data in to dataframe and look at the data we downloaded. As per the readme: The files train.csv and test.csv contain all the training samples as comma-sparated values. There are 3 columns in them, corresponding to class index (1 to 14), title and content. The title and content are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). There are no new lines in title or content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('nlp_data/dbpedia_csv/train.csv', header=None)\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('nlp_data/dbpedia_csv/test.csv', header=None)\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data<a class=\"anchor\" id=\"preprocess\"/> \n",
    "\n",
    "For the purpose of running this lab in limited time lets use subset of training data and test data to run through the Amazon Comprehend custom classification. So, we are going to use a shortened version of `train.csv` to train our custom comprehend model and we are going to use `test.csv` to perform our validation and see how well our custom model performs.\n",
    "\n",
    "Note: After the first pass of the lab you are encouraged to run the lab with all the available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traning_data = 1000 # train_data.shape[0]\n",
    "num_test_data = 100 # test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trims dataset based on max number of records per each class, \n",
    "#note that in real world scenario, when you run full dataset, classes will likely to be unbalanced.\n",
    "def trim_dataset(df, num_of_records):\n",
    "    for i in range(1, 15):\n",
    "        num = len(df[df[0] == i])\n",
    "        dropnum = num - num_of_records\n",
    "        indextodrop = df[df[0] == i].sample(n=dropnum).index\n",
    "        df.drop(indextodrop, inplace=True)\n",
    "    return df\n",
    "\n",
    "random.seed(4)\n",
    "# if you plan to use full dataset comment next 2 lines \n",
    "train_data_df = trim_dataset(train_data.copy(), num_traning_data)\n",
    "test_data_df = trim_dataset(test_data.copy(), num_test_data)\n",
    "\n",
    "# if you plan to use full dataset uncomment next 2 lines\n",
    "# train_data_df = train_data.copy()\n",
    "# test_data_df = test_Data.copy()\n",
    "\n",
    "print(\"After trimming the dataset shape of traning dataset\", train_data_df.shape, \"shape of test dataset\", test_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this only once\n",
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, the file format must conform with the [following](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification-training.html):\n",
    "\n",
    "- File must contain one label and one text per line – 2 columns\n",
    "- No header\n",
    "- Format UTF-8, carriage return “\\n”.\n",
    "\n",
    "Labels “must be uppercase, can be multitoken, have whitespace, consist of multiple words connect by underscores or hyphens or may even contain a comma in it, as long as it is correctly escaped.”\n",
    "\n",
    "Here are the proposed labels:\n",
    "\n",
    "| Index | Original | For training |\n",
    "| --- | --- | --- |\n",
    "| 1 | Company | COMPANY |\n",
    "| 2 | EducationalInstitution | EDUCATIONALINSTITUTION |\n",
    "| 3 | Artist | ARTIST |\n",
    "| 4 | Athlete | ATHLETE |\n",
    "| 5 | OfficeHolder | OFFICEHOLDER |\n",
    "| 6 | MeanOfTransportation | MEANOFTRANSPORTATION |\n",
    "| 7 | Building | BUILDING |\n",
    "| 8 | NaturalPlace | NATURALPLACE |\n",
    "| 9 | Village | VILLAGE |\n",
    "| 10 | Animal | ANIMAL |\n",
    "| 11 | Plant | PLANT |\n",
    "| 12 | Album | ALBUM |\n",
    "| 13 | Film | FILM |\n",
    "| 14 | WrittenWork | WRITTENWORK |\n",
    "\n",
    "For the inference part of it - when you want your custom model to determine which label corresponds to a given text -, the file format must conform with the following:\n",
    "\n",
    "- File must contain text per line\n",
    "- No header\n",
    "- Format UTF-8, carriage return “\\n”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {1:'COMPANY',\n",
    "               2:'EDUCATIONALINSTITUTION',\n",
    "               3:'ARTIST',\n",
    "               4:'ATHLETE',\n",
    "               5:'OFFICEHOLDER',\n",
    "               6:'MEANOFTRANSPORTATION',\n",
    "               7:'BUILDING',\n",
    "               8:'NATURALPLACE',\n",
    "               9:'VILLAGE',\n",
    "               10:'ANIMAL',\n",
    "               11:'PLANT',\n",
    "               12:'ALBUM',\n",
    "               13:'FILM',\n",
    "               14:'WRITTENWORK'\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "\n",
    "def preprocess_text(document):\n",
    "    document = denoise_text(document)\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(document))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    return document\n",
    "\n",
    "def process_data(df):\n",
    "    df[0] = df[0].apply(labels_dict.get)\n",
    "\n",
    "    df['document'] = df[df.columns[1:]].progress_apply(\n",
    "        lambda x: ' '.join(x.dropna().astype(str)),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df.drop([1, 2], axis=1, inplace=True)\n",
    "\n",
    "    df.columns = ['class', 'text']\n",
    "    \n",
    "    df['text'] = df['text'].progress_apply(preprocess_text)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = process_data(train_data_df)\n",
    "test_data_df = process_data(test_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have all the data the 2 needed files. \n",
    "\n",
    "### Building The Target Train and Test Files\n",
    "\n",
    "With all of the above spelled out the next thing to do is to build 2 distinct files:\n",
    "\n",
    "1. `comprehend-train.csv` - A CSV file containing 2 columns without header, first column class, second column text.\n",
    "1. `comprehend-test.csv` - A CSV file containing 1 column of text without header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSTTRAINFILE='comprehend-train.csv'\n",
    "DSTVALIDATIONFILE='comprehend-test.csv'\n",
    "\n",
    "train_data_df.to_csv(path_or_buf=DSTTRAINFILE,\n",
    "                  header=False,\n",
    "                  index=False,\n",
    "                  escapechar='\\\\',\n",
    "                  doublequote=False,\n",
    "                  quotechar='\"')\n",
    "\n",
    "validattion_data_df = test_data_df.copy()\n",
    "validattion_data_df.drop(['class'], axis=1, inplace=True)\n",
    "validattion_data_df.to_csv(path_or_buf=DSTVALIDATIONFILE,\n",
    "                       header=False,\n",
    "                       index=False,\n",
    "                       escapechar='\\\\',\n",
    "                       doublequote=False,\n",
    "                       quotechar='\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started With Amazon Comprehend\n",
    "Now that all of the required data to get started exists, we can start working on Comprehend Custom Classfier. \n",
    "\n",
    "The custom classifier workload is built in two steps:\n",
    "\n",
    "1. Training the custom model – no particular machine learning or deep learning knowledge is necessary\n",
    "1. Classifying new data\n",
    "\n",
    "Lets follow below steps for Training the custom model:\n",
    "\n",
    "1. Create a bucket that will host training data\n",
    "1. Create a bucket that will host training data artifacts and production results. That can be the same\n",
    "1. Configure an IAM role allowing Comprehend to [access newly created buckets](https://docs.aws.amazon.com/comprehend/latest/dg/access-control-managing-permissions.html#auth-role-permissions)\n",
    "1. Prepare data for training\n",
    "1. Upload training data in the S3 bucket\n",
    "1. Launch a “Train Classifier” job from the console: “Amazon Comprehend” > “Custom Classification” > “Train Classifier”\n",
    "1. Prepare data for classification (one text per line, no header, same format as training data). Some more details [here](https://docs.aws.amazon.com/comprehend/latest/dg/how-class-run.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the metada stored on this instance of a SageMaker Notebook determine the region we are operating in. If you are using a Jupyter Notebook outside of SageMaker simply define `region` as the string that indicates the region you would like to use for Forecast and S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure your AWS APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region) \n",
    "comprehend = session.client(service_name='comprehend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a s3 bucket that will host training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now perform the join\n",
    "print(region)\n",
    "s3 = boto3.client('s3')\n",
    "prefix = 'ComprehendDBPediaClassification'\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = account_id + \"-comprehend-dbpedia-classification-{}\".format(''.join(\n",
    "    secrets.choice(string.ascii_lowercase + string.digits) for i in range(8)))\n",
    "print(bucket_name)\n",
    "if region != \"us-east-1\":\n",
    "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
    "else:\n",
    "    s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(prefix+'/'+DSTTRAINFILE).upload_file(DSTTRAINFILE)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(prefix+'/'+DSTVALIDATIONFILE).upload_file(DSTVALIDATIONFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure an IAM role\n",
    "\n",
    "In order to authorize Amazon Comprehend to perform bucket reads and writes during the training or during the inference, we must grant Amazon Comprehend access to the Amazon S3 bucket that we created.\n",
    "\n",
    "We are going to create a data access role in our account to trust the Amazon Comprehend service principal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"ComprehendBucketAccessRole-{}\".format(''.join(\n",
    "    secrets.choice(string.ascii_lowercase + string.digits) for i in range(8)))\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"comprehend.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "policy_arn = \"arn:aws:iam::aws:policy/ComprehendFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Custom Classification model <a class=\"anchor\" id=\"#build\"/>\n",
    "\n",
    "Launch the classifier training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_data = 's3://{}/{}/{}'.format(bucket_name, prefix, DSTTRAINFILE)\n",
    "s3_output_job = 's3://{}/{}/{}'.format(bucket_name, prefix, 'output/train_job')\n",
    "print('training data location: ',s3_train_data, \"output location:\", s3_output_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "training_job = comprehend.create_document_classifier(\n",
    "    DocumentClassifierName='DBPedia-Ontology-Custom-Classifier-'+ id,\n",
    "    DataAccessRoleArn=role_arn,\n",
    "    InputDataConfig={\n",
    "        'S3Uri': s3_train_data\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': s3_output_job\n",
    "    },\n",
    "    LanguageCode='en'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobArn = training_job['DocumentClassifierArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_custom_classifier = comprehend.describe_document_classifier(\n",
    "        DocumentClassifierArn = jobArn\n",
    "    )\n",
    "    status = describe_custom_classifier[\"DocumentClassifierProperties\"][\"Status\"]\n",
    "    print(\"Custom classifier: {}\".format(status))\n",
    "    \n",
    "    if status == \"TRAINED\" or status == \"IN_ERROR\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained model confusion matrix\n",
    "\n",
    "When a custom classifier model is trained, Amazon Comprehend creates a confusion matrix that provides metrics on how well the model performed in training. This enables you to assess how well the classifier will perform when run. This matrix shows a matrix of labels as predicted by the model compared to actual labels and is created using 10 to 20 percent of the documents submitted to test the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve the S3URI from the model output and create jobkey variable.\n",
    "job_output = describe_custom_classifier[\"DocumentClassifierProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "path_prefix = 's3://{}/'.format(bucket_name)\n",
    "job_key = os.path.relpath(job_output, path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the model metrics\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).download_file(job_key, './output.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpack the gzip file\n",
    "!tar xvzf ./output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('output/confusion_matrix.json') as f:\n",
    "    comprehend_cm = json.load(f)\n",
    "\n",
    "cm_array = comprehend_cm['confusion_matrix']\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm_array, labels):\n",
    "    df_cm = pd.DataFrame(cm_array, index = [i for i in labels],\n",
    "                      columns = [i for i in labels])\n",
    "\n",
    "    #sn.set(font_scale=1.4) # for label size\n",
    "    plt.figure(figsize = (15,13))\n",
    "    sn.heatmap(df_cm, annot=True) # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(cm_array, labels = comprehend_cm['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "cm = np.array(comprehend_cm['confusion_matrix'])\n",
    "\n",
    "cols = ['label','precision', 'recall','f1_score','type']\n",
    "models_report = pd.DataFrame(columns = cols)\n",
    "\n",
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def precision_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n",
    "\n",
    "def recall_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    return (2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "def display_confusion_matrix(cm, labels, matrix_type, models_report):\n",
    "    #print(\"label precision recall f1score\")\n",
    "    for label in range(len(labels)):\n",
    "        p = precision(label, cm)\n",
    "        r = recall(label, cm)\n",
    "        f1 = f1_score(p, r)\n",
    "        #print(f\"{labels_dict.get(label)} {p:2.4f} {r:2.4f} {f1:2.4f}\")\n",
    "        tmp = pd.Series({'label': labels_dict.get(label+1),\\\n",
    "                 'precision' : p,\\\n",
    "                 'recall': r,\\\n",
    "                 'f1_score': f1,\\\n",
    "                 'type': matrix_type\n",
    "                 })\n",
    "        models_report = models_report.append(tmp, ignore_index = True)\n",
    "    #print(models_report) \n",
    "\n",
    "    p_total = precision_macro_average(cm)\n",
    "    print(f\"precision total: {p_total:2.4f}\")\n",
    "\n",
    "    r_total = recall_macro_average(cm)\n",
    "    print(f\"recall total: {r_total:2.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    a_total = accuracy(cm)\n",
    "    print(f\"accuracy total: {a_total:2.4f}\")\n",
    "\n",
    "    f1_total = f1_score(p_total, r_total)\n",
    "    print(f\"f1 total: {f1_total:2.4f}\")\n",
    "    \n",
    "    return models_report\n",
    "\n",
    "training_model_report = display_confusion_matrix(cm, comprehend_cm['labels'], 'training_matrix', models_report)\n",
    "training_model_report.sort_values(by=['f1_score'], inplace=True, ascending=False)\n",
    "print(training_model_report.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Custom Classification model <a class=\"anchor\" id=\"evaluate\"/>\n",
    "\n",
    "We will use custom classifier jobs to Evaluate on the test data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arn = describe_custom_classifier[\"DocumentClassifierProperties\"][\"DocumentClassifierArn\"]\n",
    "print(model_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_test_data = 's3://{}/{}/{}'.format(bucket_name, prefix, DSTVALIDATIONFILE)\n",
    "print(s3_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "\n",
    "start_response = comprehend.start_document_classification_job(\n",
    "    JobName = 'DBPedia-Ontology-Custom-Classifier-Inference'+ id,\n",
    "    InputDataConfig={\n",
    "        'S3Uri': s3_test_data,\n",
    "        'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': s3_output_job\n",
    "    },\n",
    "    DataAccessRoleArn=role_arn,\n",
    "    DocumentClassifierArn=model_arn\n",
    ")\n",
    "\n",
    "print(\"Start response: %s\\n\", start_response)\n",
    "\n",
    "# Check the status of the job\n",
    "describe_response = comprehend.describe_document_classification_job(JobId=start_response['JobId'])\n",
    "print(\"Describe response: %s\\n\", describe_response)\n",
    "\n",
    "# List all classification jobs in account\n",
    "list_response = comprehend.list_document_classification_jobs()\n",
    "print(\"List response: %s\\n\", list_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_response = comprehend.describe_document_classification_job(JobId=start_response['JobId'])\n",
    "    status = describe_response[\"DocumentClassificationJobProperties\"][\"JobStatus\"]\n",
    "    print(\"Custom classifier job status : {}\".format(status))\n",
    "    \n",
    "    if status == \"COMPLETED\" or status == \"FAILED\" or status == \"STOP_REQUESTED\" or status== \"STOPPED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_s3uri = describe_response[\"DocumentClassificationJobProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "path_prefix = 's3://{}/'.format(bucket_name)\n",
    "inference_job_key = os.path.relpath(inference_s3uri, path_prefix)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).download_file(inference_job_key, './inference_output.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpack the gzip file\n",
    "!tar xvzf ./inference_output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(input_path) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data\n",
    "\n",
    "inference_data = load_jsonl('predictions.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_class = []\n",
    "for line in inference_data:\n",
    "    predicted_class = sorted(line['Classes'], key=lambda x: x['Score'], reverse=True)[0]['Name']\n",
    "    inferred_class.append(predicted_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df[\"predicted_class\"] = inferred_class\n",
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate confusion metrix and other evaluation metrix for inferred results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = test_data_df['class']\n",
    "y_pred = test_data_df['predicted_class']\n",
    "labels = comprehend_cm['labels']\n",
    "cm_inference = confusion_matrix(y_true, y_pred,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_inference, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model_report = display_confusion_matrix(cm_inference, labels, 'inference_matrix', models_report)\n",
    "\n",
    "inference_model_report.sort_values(by=['f1_score'], inplace=True, ascending=False)\n",
    "print(inference_model_report.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store bucket_name\n",
    "%store region\n",
    "%store jobArn\n",
    "%store role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup <a class=\"anchor\" id=\"cleanup\"/>\n",
    "Run [clean up notebook](./Cleanup.ipynb) to clean all the resources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
