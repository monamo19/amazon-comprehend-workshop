{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Comprehend Custom Classification - Lab\n",
    "\n",
    "This notebook will serve as a template for the overall process of taking a text dataset and integrating it into [Amazon Comprehend Custom Classification](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html) and perform NLP for custom classification.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. [Introduction to Amazon Comprehend Custom Classification](#Introduction)\n",
    "1. [Obtaining Your Data](#data)\n",
    "1. [Pre-processing data](#preprocess)\n",
    "1. [Building Custom Classification model](#build)\n",
    "1. [Evaluate Custom Classification model](#evaluate)\n",
    "1. [Cleanup](#cleanup)\n",
    "\n",
    "\n",
    "## Introduction to Amazon Comprehend Custom Classification <a class=\"anchor\" id=\"Introduction\"/>\n",
    "\n",
    "If you are not familiar with Amazon Comprehend Custom Classification you can learn more about this tool on these pages:\n",
    "\n",
    "* [Product Page](https://aws.amazon.com/comprehend/)\n",
    "* [Product Docs](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification.html)\n",
    "\n",
    "\n",
    "## Bring Your Own Data <a class=\"anchor\" id=\"data\"/>\n",
    "\n",
    "We will be using Multi-Class mode in Amazon Comprehend Custom Classifier. Multi-class mode specifies a single class for each document. The individual classes are mutually exclusive, this part is important. If we have an overlapping classes, it is best to set expectaion that our model will learn and try predict same overlapping classes and accuracy might be impacted.\n",
    "\n",
    "We are going to upload custom dataset. We ensure that dataset is a .csv and the format of the file must be one class and document per line. For example:\n",
    "```\n",
    "CLASS,Text of document 1\n",
    "CLASS,Text of document 2\n",
    "CLASS,Text of document 3\n",
    "```\n",
    "if we dont have the file in above fomat, we will convert it to above format.\n",
    "\n",
    "To begin the cell below will complete the following:\n",
    "\n",
    "1. Create a directory for the data files.\n",
    "1. Upload the file manually to the nlp_data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir nlp_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data downloaded, now we will import the Pandas library as well as a few other data science tools in order to inspect the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import secrets\n",
    "import string\n",
    "import datetime \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this only once\n",
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the data in to dataframe and look at the data we uploaded. Examine the number of columns that are present. Look at few samples to see the content of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('nlp_data/raw_data.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['CATEGORY_NAME'] = raw_data['CATEGORY_NAME'].astype(str)\n",
    "raw_data.groupby('CATEGORY_NAME')['CASE_SUBJECT_FULL'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert data to the format that is required by Amazon Comprehend Custom Classifier,\n",
    "\n",
    "```\n",
    "CLASS,Text of document 1\n",
    "CLASS,Text of document 2\n",
    "CLASS,Text of document 3\n",
    "```\n",
    "We will identify the column which are class and which have the text content we would like to train on, we can create a new dataframe with selected columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['CATEGORY_NAME', 'CASE_SUBJECT_FULL', 'CASE_DESCRIPTION_FULL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns we are interested in\n",
    "selected_data = raw_data[selected_columns]\n",
    "selected_data = selected_data[selected_data['CATEGORY_NAME']!='Not Known']\n",
    "selected_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_data.groupby('CATEGORY_NAME')['CASE_SUBJECT_FULL'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we might be interested in finding outt he accuracy level of the model compared to known labels, we want to held out 10% dataset for later use to infer from the comdel, generate performanace matrix to asses the model. We want to stratify split data based on 'CATEGORY_NAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(selected_data, test_size=0.1, random_state=0, \n",
    "                               stratify=selected_data[['CATEGORY_NAME']])\n",
    "\n",
    "train_data_df = train_data.copy()\n",
    "test_data_df = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data<a class=\"anchor\" id=\"preprocess\"/> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, the file format must conform with the [following](https://docs.aws.amazon.com/comprehend/latest/dg/how-document-classification-training.html):\n",
    "\n",
    "- File must contain one label and one text per line – 2 columns\n",
    "- No header\n",
    "- Format UTF-8, carriage return “\\n”.\n",
    "\n",
    "Labels “must be uppercase, can be multitoken, have whitespace, consist of multiple words connect by underscores or hyphens or may even contain a comma in it, as long as it is correctly escaped.”\n",
    "\n",
    "Here are the proposed labels:\n",
    "\n",
    "| Index | Original | For training |\n",
    "| --- | --- | --- |\n",
    "| 1 | Company | COMPANY |\n",
    "| 2 | EducationalInstitution | EDUCATIONALINSTITUTION |\n",
    "| 3 | Artist | ARTIST |\n",
    "| 4 | Athlete | ATHLETE |\n",
    "| 5 | OfficeHolder | OFFICEHOLDER |\n",
    "| 6 | MeanOfTransportation | MEANOFTRANSPORTATION |\n",
    "| 7 | Building | BUILDING |\n",
    "| 8 | NaturalPlace | NATURALPLACE |\n",
    "| 9 | Village | VILLAGE |\n",
    "| 10 | Animal | ANIMAL |\n",
    "| 11 | Plant | PLANT |\n",
    "| 12 | Album | ALBUM |\n",
    "| 13 | Film | FILM |\n",
    "| 14 | WrittenWork | WRITTENWORK |\n",
    "\n",
    "For the inference part of it - when you want your custom model to determine which label corresponds to a given text -, the file format must conform with the following:\n",
    "\n",
    "- File must contain text per line\n",
    "- No header\n",
    "- Format UTF-8, carriage return “\\n”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {'1':'COMPANY',\n",
    "               '2':'EDUCATIONALINSTITUTION',\n",
    "               '3':'ARTIST',\n",
    "               '4':'ATHLETE',\n",
    "               '5':'OFFICEHOLDER',\n",
    "               '6':'MEANOFTRANSPORTATION',\n",
    "               '7':'BUILDING',\n",
    "               '8':'NATURALPLACE',\n",
    "               '9':'VILLAGE',\n",
    "               '10':'ANIMAL',\n",
    "               '11':'PLANT',\n",
    "               '12':'ALBUM',\n",
    "               '13':'FILM',\n",
    "               '14':'WRITTENWORK'\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "\n",
    "def preprocess_text(document):\n",
    "    document = denoise_text(document)\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(document))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    return document\n",
    "\n",
    "def process_data(df):\n",
    "    df['CATEGORY_NAME'] = df['CATEGORY_NAME'].apply(labels_dict.get)\n",
    "\n",
    "    df['document'] = df[df.columns[1:]].progress_apply(\n",
    "        lambda x: ' '.join(x.dropna().astype(str)),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df.drop(['CASE_SUBJECT_FULL' ,'CASE_DESCRIPTION_FULL'], axis=1, inplace=True)\n",
    "\n",
    "    df.columns = ['class', 'text']\n",
    "    \n",
    "    df['text'] = df['text'].progress_apply(preprocess_text)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = process_data(train_data_df)\n",
    "test_data_df = process_data(test_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have all the data the 2 needed files. \n",
    "\n",
    "### Building The Target Train and Test Files\n",
    "\n",
    "With all of the above spelled out the next thing to do is to build 2 distinct files:\n",
    "\n",
    "1. `comprehend-train.csv` - A CSV file containing 2 columns without header, first column class, second column text.\n",
    "1. `comprehend-test.csv` - A CSV file containing 1 column of text without header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSTTRAINFILE='nlp_data/comprehend-train.csv'\n",
    "DSTVALIDATIONFILE='nlp_data/comprehend-test.csv'\n",
    "\n",
    "train_data_df.to_csv(path_or_buf=DSTTRAINFILE,\n",
    "                  header=False,\n",
    "                  index=False,\n",
    "                  escapechar='\\\\',\n",
    "                  doublequote=False,\n",
    "                  quotechar='\"')\n",
    "\n",
    "validattion_data_df = test_data_df.copy()\n",
    "validattion_data_df.drop(['class'], axis=1, inplace=True)\n",
    "validattion_data_df.to_csv(path_or_buf=DSTVALIDATIONFILE,\n",
    "                       header=False,\n",
    "                       index=False,\n",
    "                       escapechar='\\\\',\n",
    "                       doublequote=False,\n",
    "                       quotechar='\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started With Amazon Comprehend\n",
    "Now that all of the required data to get started exists, we can start working on Comprehend Custom Classfier. \n",
    "\n",
    "The custom classifier workload is built in two steps:\n",
    "\n",
    "1. Training the custom model – no particular machine learning or deep learning knowledge is necessary\n",
    "1. Classifying new data\n",
    "\n",
    "Lets follow below steps for Training the custom model:\n",
    "\n",
    "1. Create a bucket that will host training data\n",
    "1. Create a bucket that will host training data artifacts and production results. That can be the same\n",
    "1. Configure an IAM role allowing Comprehend to [access newly created buckets](https://docs.aws.amazon.com/comprehend/latest/dg/access-control-managing-permissions.html#auth-role-permissions)\n",
    "1. Prepare data for training\n",
    "1. Upload training data in the S3 bucket\n",
    "1. Launch a “Train Classifier” job from the console: “Amazon Comprehend” > “Custom Classification” > “Train Classifier”\n",
    "1. Prepare data for classification (one text per line, no header, same format as training data). Some more details [here](https://docs.aws.amazon.com/comprehend/latest/dg/how-class-run.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the metada stored on this instance of a SageMaker Notebook determine the region we are operating in. If you are using a Jupyter Notebook outside of SageMaker simply define `region` as the string that indicates the region you would like to use for Forecast and S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure your AWS APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region) \n",
    "comprehend = session.client(service_name='comprehend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a s3 bucket that will host training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now perform the join\n",
    "print(region)\n",
    "s3 = boto3.client('s3')\n",
    "prefix = 'ComprehendDBPediaClassification'\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = account_id + \"-comprehend-dbpedia-classification-{}\".format(''.join(\n",
    "    secrets.choice(string.ascii_lowercase + string.digits) for i in range(8)))\n",
    "print(bucket_name)\n",
    "if region != \"us-east-1\":\n",
    "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})\n",
    "else:\n",
    "    s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(prefix+'/'+DSTTRAINFILE).upload_file(DSTTRAINFILE)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(prefix+'/'+DSTVALIDATIONFILE).upload_file(DSTVALIDATIONFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure an IAM role\n",
    "\n",
    "In order to authorize Amazon Comprehend to perform bucket reads and writes during the training or during the inference, we must grant Amazon Comprehend access to the Amazon S3 bucket that we created.\n",
    "\n",
    "We are going to create a data access role in our account to trust the Amazon Comprehend service principal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"ComprehendBucketAccessRole-{}\".format(''.join(\n",
    "    secrets.choice(string.ascii_lowercase + string.digits) for i in range(8)))\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"comprehend.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "policy_arn = \"arn:aws:iam::aws:policy/ComprehendFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Custom Classification model <a class=\"anchor\" id=\"#build\"/>\n",
    "\n",
    "Launch the classifier training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_data = 's3://{}/{}/{}'.format(bucket_name, prefix, DSTTRAINFILE)\n",
    "s3_output_job = 's3://{}/{}/{}'.format(bucket_name, prefix, 'output/train_job')\n",
    "print('training data location: ',s3_train_data, \"output location:\", s3_output_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "training_job = comprehend.create_document_classifier(\n",
    "    DocumentClassifierName='DBPedia-Ontology-Custom-Classifier-'+ id,\n",
    "    DataAccessRoleArn=role_arn,\n",
    "    InputDataConfig={\n",
    "        'S3Uri': s3_train_data\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': s3_output_job\n",
    "    },\n",
    "    LanguageCode='en'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobArn = training_job['DocumentClassifierArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_custom_classifier = comprehend.describe_document_classifier(\n",
    "        DocumentClassifierArn = jobArn\n",
    "    )\n",
    "    status = describe_custom_classifier[\"DocumentClassifierProperties\"][\"Status\"]\n",
    "    print(\"Custom classifier: {}\".format(status))\n",
    "    \n",
    "    if status == \"TRAINED\" or status == \"IN_ERROR\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained model confusion matrix\n",
    "\n",
    "When a custom classifier model is trained, Amazon Comprehend creates a confusion matrix that provides metrics on how well the model performed in training. This enables you to assess how well the classifier will perform when run. This matrix shows a matrix of labels as predicted by the model compared to actual labels and is created using 10 to 20 percent of the documents submitted to test the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve the S3URI from the model output and create jobkey variable.\n",
    "job_output = describe_custom_classifier[\"DocumentClassifierProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "path_prefix = 's3://{}/'.format(bucket_name)\n",
    "job_key = os.path.relpath(job_output, path_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the model metrics\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).download_file(job_key, './output.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpack the gzip file\n",
    "!tar xvzf ./output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('output/confusion_matrix.json') as f:\n",
    "    comprehend_cm = json.load(f)\n",
    "\n",
    "cm_array = comprehend_cm['confusion_matrix']\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm_array, labels):\n",
    "    df_cm = pd.DataFrame(cm_array, index = [i for i in labels],\n",
    "                      columns = [i for i in labels])\n",
    "\n",
    "    #sn.set(font_scale=1.4) # for label size\n",
    "    plt.figure(figsize = (15,13))\n",
    "    sn.heatmap(df_cm, annot=True) # font size\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(cm_array, labels = comprehend_cm['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "cm = np.array(comprehend_cm['confusion_matrix'])\n",
    "\n",
    "cols = ['label','precision', 'recall','f1_score','type']\n",
    "models_report = pd.DataFrame(columns = cols)\n",
    "\n",
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()\n",
    "\n",
    "def precision_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_precisions = 0\n",
    "    for label in range(rows):\n",
    "        sum_of_precisions += precision(label, confusion_matrix)\n",
    "    return sum_of_precisions / rows\n",
    "\n",
    "def recall_macro_average(confusion_matrix):\n",
    "    rows, columns = confusion_matrix.shape\n",
    "    sum_of_recalls = 0\n",
    "    for label in range(columns):\n",
    "        sum_of_recalls += recall(label, confusion_matrix)\n",
    "    return sum_of_recalls / columns\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    return (2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements \n",
    "\n",
    "def display_confusion_matrix(cm, labels, matrix_type, models_report):\n",
    "    #print(\"label precision recall f1score\")\n",
    "    for label in range(len(labels)):\n",
    "        p = precision(label, cm)\n",
    "        r = recall(label, cm)\n",
    "        f1 = f1_score(p, r)\n",
    "        #print(f\"{labels_dict.get(label)} {p:2.4f} {r:2.4f} {f1:2.4f}\")\n",
    "        tmp = pd.Series({'label': labels_dict.get(label+1),\\\n",
    "                 'precision' : p,\\\n",
    "                 'recall': r,\\\n",
    "                 'f1_score': f1,\\\n",
    "                 'type': matrix_type\n",
    "                 })\n",
    "        models_report = models_report.append(tmp, ignore_index = True)\n",
    "    #print(models_report) \n",
    "\n",
    "    p_total = precision_macro_average(cm)\n",
    "    print(f\"precision total: {p_total:2.4f}\")\n",
    "\n",
    "    r_total = recall_macro_average(cm)\n",
    "    print(f\"recall total: {r_total:2.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    a_total = accuracy(cm)\n",
    "    print(f\"accuracy total: {a_total:2.4f}\")\n",
    "\n",
    "    f1_total = f1_score(p_total, r_total)\n",
    "    print(f\"f1 total: {f1_total:2.4f}\")\n",
    "    \n",
    "    return models_report\n",
    "\n",
    "training_model_report = display_confusion_matrix(cm, comprehend_cm['labels'], 'training_matrix', models_report)\n",
    "training_model_report.sort_values(by=['f1_score'], inplace=True, ascending=False)\n",
    "print(training_model_report.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Custom Classification model <a class=\"anchor\" id=\"evaluate\"/>\n",
    "\n",
    "We will use custom classifier jobs to Evaluate on the test data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arn = describe_custom_classifier[\"DocumentClassifierProperties\"][\"DocumentClassifierArn\"]\n",
    "print(model_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_test_data = 's3://{}/{}/{}'.format(bucket_name, prefix, DSTVALIDATIONFILE)\n",
    "print(s3_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "\n",
    "start_response = comprehend.start_document_classification_job(\n",
    "    JobName = 'DBPedia-Ontology-Custom-Classifier-Inference'+ id,\n",
    "    InputDataConfig={\n",
    "        'S3Uri': s3_test_data,\n",
    "        'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': s3_output_job\n",
    "    },\n",
    "    DataAccessRoleArn=role_arn,\n",
    "    DocumentClassifierArn=model_arn\n",
    ")\n",
    "\n",
    "print(\"Start response: %s\\n\", start_response)\n",
    "\n",
    "# Check the status of the job\n",
    "describe_response = comprehend.describe_document_classification_job(JobId=start_response['JobId'])\n",
    "print(\"Describe response: %s\\n\", describe_response)\n",
    "\n",
    "# List all classification jobs in account\n",
    "list_response = comprehend.list_document_classification_jobs()\n",
    "print(\"List response: %s\\n\", list_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_response = comprehend.describe_document_classification_job(JobId=start_response['JobId'])\n",
    "    status = describe_response[\"DocumentClassificationJobProperties\"][\"JobStatus\"]\n",
    "    print(\"Custom classifier job status : {}\".format(status))\n",
    "    \n",
    "    if status == \"COMPLETED\" or status == \"FAILED\" or status == \"STOP_REQUESTED\" or status== \"STOPPED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_s3uri = describe_response[\"DocumentClassificationJobProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "path_prefix = 's3://{}/'.format(bucket_name)\n",
    "inference_job_key = os.path.relpath(inference_s3uri, path_prefix)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).download_file(inference_job_key, './inference_output.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpack the gzip file\n",
    "!tar xvzf ./inference_output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(input_path) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data\n",
    "\n",
    "inference_data = load_jsonl('predictions.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_class = []\n",
    "for line in inference_data:\n",
    "    predicted_class = sorted(line['Classes'], key=lambda x: x['Score'], reverse=True)[0]['Name']\n",
    "    inferred_class.append(predicted_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df[\"predicted_class\"] = inferred_class\n",
    "test_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate confusion metrix and other evaluation metrix for inferred results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = test_data_df['class']\n",
    "y_pred = test_data_df['predicted_class']\n",
    "labels = comprehend_cm['labels']\n",
    "cm_inference = confusion_matrix(y_true, y_pred,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_inference, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model_report = display_confusion_matrix(cm_inference, labels, 'inference_matrix', models_report)\n",
    "\n",
    "inference_model_report.sort_values(by=['f1_score'], inplace=True, ascending=False)\n",
    "print(inference_model_report.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store bucket_name\n",
    "%store region\n",
    "%store jobArn\n",
    "%store role_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup <a class=\"anchor\" id=\"cleanup\"/>\n",
    "Run [clean up notebook](./Cleanup.ipynb) to clean all the resources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}